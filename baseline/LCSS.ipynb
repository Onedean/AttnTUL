{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '..\\data\\geolife\\geolife-all.csv'\n",
    "tracks_data = pd.read_csv(raw_path, sep='\\t')\n",
    "\n",
    "split_ratio  = 0.8\n",
    "\n",
    "all_poi = tracks_data['poi1'].drop_duplicates().values.tolist()\n",
    "poi2idx = {poi:idx+1 for idx, poi in enumerate(all_poi)}\n",
    "poi2idx['pad'] = 0\n",
    "\n",
    "\n",
    "user_list = tracks_data['ObjectID'].drop_duplicates().values.tolist()\n",
    "user_traj_dict = {key:[] for key in user_list}\n",
    "for user_id in tqdm(tracks_data['ObjectID'].drop_duplicates().values.tolist()):\n",
    "    one_user_data = tracks_data.loc[tracks_data.ObjectID == user_id, :]\n",
    "    for traj_id in one_user_data['TrajNumber'].drop_duplicates().values.tolist():\n",
    "        one_traj_data = one_user_data.loc[tracks_data.TrajNumber == traj_id, 'poi1'].values.tolist()\n",
    "        user_traj_dict[user_id].append(one_traj_data)\n",
    "\n",
    "user_traj_train, user_traj_test = {key:[] for key in user_list}, {key:[] for key in user_list}\n",
    "\n",
    "for key in user_traj_dict:\n",
    "    traj_num = len(user_traj_dict[key])\n",
    "\n",
    "    for idx in list(range(traj_num))[:int(traj_num * split_ratio)]:\n",
    "        user_traj_train[key].append([poi2idx[poi] for poi in user_traj_dict[key][idx]])\n",
    "    \n",
    "    for idx in list(range(traj_num))[int(traj_num * split_ratio):]:\n",
    "        user_traj_test[key].append([poi2idx[poi] for poi in user_traj_dict[key][idx]])\n",
    "\n",
    "print('poi number:', len(poi2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(a, b):\n",
    "    lena = len(a)\n",
    "    lenb = len(b)\n",
    "    c = [[0 for i in range(lenb + 1)] for j in range(lena + 1)]\n",
    "    flag = [[0 for i in range(lenb + 1)] for j in range(lena + 1)]\n",
    "    for i in range(lena):\n",
    "        for j in range(lenb):\n",
    "            if a[i] == b[j]:\n",
    "                c[i + 1][j + 1] = c[i][j] + 1\n",
    "                flag[i + 1][j + 1] = 'ok'\n",
    "            elif c[i + 1][j] > c[i][j + 1]:\n",
    "                c[i + 1][j + 1] = c[i + 1][j]\n",
    "                flag[i + 1][j + 1] = 'left'\n",
    "            else:\n",
    "                c[i + 1][j + 1] = c[i][j + 1]\n",
    "                flag[i + 1][j + 1] = 'up'\n",
    "    calLcs.count = 0\n",
    "    calLcs(flag, a, len(a), len(b))\n",
    "    return calLcs.count / min(lena, lenb)\n",
    "\n",
    "\n",
    "def calLcs(flag, a, i, j):\n",
    "    if i == 0 or j == 0:\n",
    "        return\n",
    "    if flag[i][j] == 'ok':\n",
    "        calLcs(flag, a, i - 1, j - 1)\n",
    "        calLcs.count += 1\n",
    "    elif flag[i][j] == 'left':\n",
    "        calLcs(flag, a, i, j - 1)\n",
    "    else:\n",
    "        calLcs(flag, a, i - 1, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [1:45:57<00:00, 70.64s/it]Result:\n",
      " acc1_test:0.3041 \t  acc5_test:0.5800 \t Macro-P:0.3519 \t Macro-R:0.2657 \t Macro-F1:0.2634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_predict_list, y_true_list, acc1_list, acc5_list = [], [], [], []\n",
    "\n",
    "for test_user in tqdm(user_traj_test):\n",
    "    for one_test_traj in user_traj_test[test_user]:\n",
    "        pred, target, sim = [], [], 0\n",
    "        for train_user in user_traj_train:\n",
    "            for one_train_traj in user_traj_train[train_user]:\n",
    "                sim = lcs(one_test_traj, one_train_traj)\n",
    "                pred.append(sim)\n",
    "                target.append(train_user)\n",
    "        predict_user = target[pred.index(max(pred))]\n",
    "        y_predict_list.append(predict_user)\n",
    "        y_true_list.append(test_user)\n",
    "        acc1_list.append(predict_user == test_user)\n",
    "        acc5_list.append(test_user in [target[idx] for idx in heapq.nlargest(5, range(len(pred)), pred.__getitem__)])\n",
    "\n",
    "p = precision_score(y_true_list, y_predict_list, average='macro')\n",
    "r = recall_score(y_true_list, y_predict_list, average='macro')\n",
    "f1 = f1_score( y_true_list, y_predict_list, average='macro')\n",
    "\n",
    "print(\"Result:\\n acc1_test:{:.4f} \\t  acc5_test:{:.4f} \\t Macro-P:{:.4f} \\t Macro-R:{:.4f} \\t Macro-F1:{:.4f}\".format(np.mean(acc1_list), np.mean(acc5_list), p, r ,f1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d6fe1219e01d7dafee20731a05552605019c0a7a7b347a5872aa19530480494"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
